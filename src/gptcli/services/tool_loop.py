# src/gptcli/services/tool_loop.py
"""
Tool ì‹¤í–‰ ë£¨í”„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°.

AI ì‘ë‹µì— tool_callsê°€ í¬í•¨ëœ ê²½ìš°, ê° Toolì„ ì‹¤í–‰í•˜ê³ 
ê·¸ ê²°ê³¼ë¥¼ ë‹¤ì‹œ AIì— ì „ë‹¬í•˜ëŠ” ë£¨í”„ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.

íë¦„:
1. ì‚¬ìš©ì ì…ë ¥ â†’ AI í˜¸ì¶œ (tools í¬í•¨)
2. AI ì‘ë‹µì— tool_calls ìˆìŒ?
   - No â†’ ì‘ë‹µ ì¶œë ¥ ë° ì¢…ë£Œ
   - Yes â†’ ê° tool ì‹¤í–‰ â†’ ê²°ê³¼ë¥¼ messagesì— ì¶”ê°€ â†’ 2ë²ˆìœ¼ë¡œ ë°˜ë³µ
3. ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ ê²½ê³  í›„ ì¢…ë£Œ
"""
from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from rich.console import Console

from src.gptcli.tools.registry import ToolRegistry
from src.gptcli.tools.permission import TrustLevel
from src.gptcli.tools.schemas import TOOL_SCHEMAS
from src.gptcli.services.ai_stream import AIStreamParser
from src.gptcli.models.capabilities import supports_tools, get_supported_parameters


class ToolLoopService:
    """
    Tool ì‹¤í–‰ ë£¨í”„ë¥¼ ê´€ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤.

    AIê°€ tool_callsë¥¼ ë°˜í™˜í•˜ë©´, ê° Toolì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë‹¤ì‹œ
    AIì— ì „ë‹¬í•˜ëŠ” ë£¨í”„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """

    # ìµœëŒ€ ë£¨í”„ ë°˜ë³µ íšŸìˆ˜ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
    MAX_ITERATIONS: int = 50

    def __init__(
        self,
        base_dir: Path,
        console: Console,
        parser: AIStreamParser,
        trust_level: TrustLevel = TrustLevel.FULL
    ):
        """
        Args:
            base_dir: í”„ë¡œì íŠ¸ ê¸°ë³¸ ë””ë ‰í„°ë¦¬
            console: Rich Console ì¸ìŠ¤í„´ìŠ¤
            parser: AIStreamParser ì¸ìŠ¤í„´ìŠ¤
            trust_level: ì´ˆê¸° ì‹ ë¢° ìˆ˜ì¤€
        """
        self.base_dir = base_dir
        self.console = console
        self.parser = parser
        self.registry = ToolRegistry(base_dir, console, trust_level)

        # Tool ëª¨ë“œ í™œì„±í™” ì—¬ë¶€
        self.enabled: bool = True
        # Tool ê°•ì œ ëª¨ë“œ (tool_choice: "required")
        self.force_mode: bool = False

    def set_enabled(self, enabled: bool) -> None:
        """Tool ëª¨ë“œë¥¼ í™œì„±í™”/ë¹„í™œì„±í™”í•©ë‹ˆë‹¤."""
        self.enabled = enabled
        status = "í™œì„±í™”" if enabled else "ë¹„í™œì„±í™”"
        self.console.print(f"[green]Tool ëª¨ë“œ {status}ë¨[/green]", highlight=False)

    def set_force_mode(self, force: bool) -> None:
        """Tool ê°•ì œ ëª¨ë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
        self.force_mode = force
        if force:
            self.console.print(
                "[yellow]ğŸ”§ Tool ê°•ì œ ëª¨ë“œ ON[/yellow] - ëª¨ë¸ì´ í•­ìƒ Toolì„ ì‚¬ìš©í•©ë‹ˆë‹¤.",
                highlight=False
            )
            self.console.print(
                "[dim]ì£¼ì˜: ì¼ë°˜ ëŒ€í™”ì—ì„œë„ Toolì„ í˜¸ì¶œí•˜ë¯€ë¡œ ë¶€ìì—°ìŠ¤ëŸ¬ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.[/dim]",
                highlight=False
            )
        else:
            self.console.print(
                "[green]ğŸ”§ Tool ê°•ì œ ëª¨ë“œ OFF[/green] - ëª¨ë¸ì´ ìë™ìœ¼ë¡œ Tool ì‚¬ìš© ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.",
                highlight=False
            )

    def set_trust_level(self, level: TrustLevel) -> None:
        """ì‹ ë¢° ìˆ˜ì¤€ì„ ë³€ê²½í•©ë‹ˆë‹¤."""
        self.registry.set_trust_level(level)

    def _get_tool_calls_signature(self, tool_calls: List[Dict[str, Any]]) -> str:
        """
        tool_callsì˜ ì‹œê·¸ë‹ˆì²˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (ë°˜ë³µ ê°ì§€ìš©).

        ë™ì¼í•œ Toolì„ ë™ì¼í•œ ì¸ìë¡œ í˜¸ì¶œí•˜ë©´ ê°™ì€ ì‹œê·¸ë‹ˆì²˜ê°€ ë©ë‹ˆë‹¤.
        ì´ë¥¼ í†µí•´ ë¬´í•œ ë£¨í”„(ê°™ì€ ì‘ì—… ë°˜ë³µ)ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
        """
        parts = []
        for tc in tool_calls:
            func = tc.get("function", {})
            name = func.get("name", "")
            args = func.get("arguments", "")
            parts.append(f"{name}:{args}")
        return "|".join(sorted(parts))

    def get_trust_status(self) -> str:
        """í˜„ì¬ ì‹ ë¢° ìƒíƒœ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.registry.get_trust_status()

    def get_tools_for_api(self, model: str) -> Tuple[Optional[List[Dict[str, Any]]], str]:
        """
        API í˜¸ì¶œì— ì „ë‹¬í•  tools íŒŒë¼ë¯¸í„°ì™€ tool_choiceë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        Tool ëª¨ë“œê°€ ë¹„í™œì„±í™”ë˜ì—ˆê±°ë‚˜ ëª¨ë¸ì´ toolsë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë©´ (None, "auto")ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            model: ëª¨ë¸ ID (tool ì§€ì› ì—¬ë¶€ í™•ì¸ìš©)

        Returns:
            (Tool ìŠ¤í‚¤ë§ˆ ëª©ë¡ ë˜ëŠ” None, tool_choice ê°’)
        """
        if not self.enabled:
            return None, "auto"

        # ëª¨ë¸ì´ toolsë¥¼ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸
        if not supports_tools(model):
            return None, "auto"

        # ê°•ì œ ëª¨ë“œë©´ "required", ì•„ë‹ˆë©´ "auto"
        tool_choice = "required" if self.force_mode else "auto"
        return TOOL_SCHEMAS, tool_choice

    def check_model_tool_support(self, model: str) -> Tuple[bool, List[str]]:
        """
        ëª¨ë¸ì˜ Tool ì§€ì› ì—¬ë¶€ì™€ ì§€ì› íŒŒë¼ë¯¸í„°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

        Args:
            model: ëª¨ë¸ ID

        Returns:
            (supports_tools, supported_parameters) íŠœí”Œ
        """
        has_support = supports_tools(model)
        params = get_supported_parameters(model)
        return has_support, params

    def run_with_tools(
        self,
        system_prompt: Dict[str, Any],
        messages: List[Dict[str, Any]],
        model: str,
        pretty_print: bool = True
    ) -> Optional[Tuple[str, Dict[str, Any]]]:
        """
        Tool ì‹¤í–‰ ë£¨í”„ë¥¼ í¬í•¨í•œ AI í˜¸ì¶œì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°ì²´
            messages: ëŒ€í™” ë©”ì‹œì§€ ëª©ë¡ (ì´ ëª©ë¡ì€ ìˆ˜ì •ë˜ì§€ ì•ŠìŒ - ì„ì‹œ ë³µì‚¬ë³¸ ì‚¬ìš©)
            model: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
            pretty_print: ê³ ê¸‰ ì¶œë ¥ ëª¨ë“œ ì—¬ë¶€

        Returns:
            (ìµœì¢… ì‘ë‹µ ë¬¸ìì—´, ì‚¬ìš©ëŸ‰ ì •ë³´) íŠœí”Œ.
            ì‹¤íŒ¨ ì‹œ None.

        Note:
            Tool ì‹¤í–‰ ì¤‘ê°„ ë©”ì‹œì§€(tool_calls, tool results)ëŠ” ì„¸ì…˜ì— ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            ì˜¤ì§ ìµœì¢… í…ìŠ¤íŠ¸ ì‘ë‹µë§Œ ë°˜í™˜í•˜ì—¬ ì €ì¥í•˜ë„ë¡ í•©ë‹ˆë‹¤.
            ì´ëŠ” Anthropic APIì˜ tool_use/tool_result í˜ì–´ë§ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±ì‹œí‚¤ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.
        """
        # ëª¨ë¸ Tool ì§€ì› ì—¬ë¶€ í™•ì¸
        tools, tool_choice = self.get_tools_for_api(model)
        has_support, params = self.check_model_tool_support(model)

        # ë””ë²„ê·¸: ëª¨ë¸ì˜ Tool ì§€ì› ìƒíƒœ ì¶œë ¥
        model_short = model.split("/")[-1] if "/" in model else model

        if self.enabled:
            force_indicator = " [ê°•ì œ]" if self.force_mode else ""
            if has_support:
                self.console.print(
                    f"[dim]ğŸ”§ ëª¨ë¸ '{model_short}'ì˜ Tool ì§€ì›: âœ…{force_indicator}[/dim]",
                    highlight=False
                )
            else:
                self.console.print(
                    f"[dim]ğŸ”§ ëª¨ë¸ '{model_short}'ì˜ Tool ì§€ì›: âŒ (supported_params={params})[/dim]",
                    highlight=False
                )

        # ëª¨ë¸ì´ toolsë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë©´ ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥
        if self.enabled and tools is None:
            if not has_support:
                self.console.print(
                    f"\n[yellow]âš ï¸ '{model_short}' ëª¨ë¸ì€ Tool Callingì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.[/yellow]",
                    highlight=False
                )
                self.console.print(
                    "[dim]Tool ì—†ì´ ì¼ë°˜ ëŒ€í™” ëª¨ë“œë¡œ ì§„í–‰í•©ë‹ˆë‹¤. "
                    "Toolì„ ì‚¬ìš©í•˜ë ¤ë©´ ì§€ì› ëª¨ë¸ë¡œ ë³€ê²½í•˜ì„¸ìš” "
                    "(ì˜ˆ: anthropic/claude-opus-4, openai/gpt-4o)[/dim]",
                    highlight=False
                )

        iteration = 0
        final_response = ""
        final_usage = None

        # ì›ë³¸ messagesë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³  ì„ì‹œ ë³µì‚¬ë³¸ ì‚¬ìš©
        working_messages = list(messages)

        # ë°˜ë³µ ê°ì§€ìš©: ì´ì „ tool_calls ê¸°ë¡
        previous_tool_calls_signature = None
        repeat_count = 0
        MAX_REPEATS = 2  # ë™ì¼ ì‘ì—… ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜

        # Tool force ëª¨ë“œì—ì„œ ì“°ê¸° ì—†ì´ ì½ê¸°ë§Œ ë°˜ë³µí•˜ëŠ” ê²½ìš° ê°ì§€
        WRITE_TOOLS = {"Write", "Edit", "Bash"}
        consecutive_read_only = 0
        MAX_READ_ONLY_ITERATIONS = 5  # ì—°ì† 5íšŒ ì½ê¸°ë§Œ í•˜ë©´ ê²½ê³ 

        while iteration < self.MAX_ITERATIONS:
            iteration += 1

            # AI í˜¸ì¶œ
            result = self.parser.stream_and_parse(
                system_prompt,
                working_messages,
                model,
                pretty_print,
                tools=tools,
                tool_choice=tool_choice
            )

            if result is None:
                return None

            response_text, usage_info, tool_calls = result
            final_response = response_text
            final_usage = usage_info

            # tool_callsê°€ ì—†ìœ¼ë©´ ë£¨í”„ ì¢…ë£Œ (ìµœì¢… í…ìŠ¤íŠ¸ ì‘ë‹µ)
            if not tool_calls:
                break

            # ë°˜ë³µ ê°ì§€: ë™ì¼í•œ tool_calls íŒ¨í„´ì¸ì§€ í™•ì¸
            current_signature = self._get_tool_calls_signature(tool_calls)
            if current_signature == previous_tool_calls_signature:
                repeat_count += 1
                if repeat_count >= MAX_REPEATS:
                    self.console.print(
                        f"\n[yellow]âš ï¸ ë™ì¼í•œ Tool í˜¸ì¶œì´ {MAX_REPEATS}íšŒ ë°˜ë³µë¨. ë¬´í•œ ë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•´ ì¢…ë£Œí•©ë‹ˆë‹¤.[/yellow]",
                        highlight=False
                    )
                    # tool_choiceë¥¼ noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìµœì¢… ì‘ë‹µ ìš”ì²­
                    self.console.print(
                        "[dim]â†’ ëª¨ë¸ì— ìµœì¢… ì‘ë‹µ ìš”ì²­ ì¤‘...[/dim]",
                        highlight=False
                    )
                    final_result = self.parser.stream_and_parse(
                        system_prompt,
                        working_messages,
                        model,
                        pretty_print,
                        tools=None  # Tool ì—†ì´ ìµœì¢… ì‘ë‹µ ìš”ì²­
                    )
                    if final_result:
                        final_response = final_result[0]
                        final_usage = final_result[1]
                    break
            else:
                repeat_count = 0
                previous_tool_calls_signature = current_signature

            # Tool force ëª¨ë“œì—ì„œ ì“°ê¸° Tool ì—†ì´ ì½ê¸°ë§Œ ë°˜ë³µí•˜ëŠ”ì§€ ì²´í¬
            if self.force_mode:
                tool_names = [tc.get("function", {}).get("name", "") for tc in tool_calls]
                has_write_tool = any(name in WRITE_TOOLS for name in tool_names)

                if has_write_tool:
                    consecutive_read_only = 0  # ì“°ê¸° Tool ì‚¬ìš© ì‹œ ì¹´ìš´í„° ë¦¬ì…‹
                else:
                    consecutive_read_only += 1
                    if consecutive_read_only >= MAX_READ_ONLY_ITERATIONS:
                        self.console.print(
                            f"\n[yellow]âš ï¸ Tool ê°•ì œ ëª¨ë“œì—ì„œ {MAX_READ_ONLY_ITERATIONS}íšŒ ì—°ì† ì½ê¸°ë§Œ ìˆ˜í–‰ë¨.[/yellow]",
                            highlight=False
                        )
                        self.console.print(
                            "[dim]â†’ ëª¨ë¸ì´ ìˆ˜ì •ì„ ìˆ˜í–‰í•˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤. ìµœì¢… ì‘ë‹µ ìš”ì²­ ì¤‘...[/dim]",
                            highlight=False
                        )
                        # Tool ì—†ì´ ìµœì¢… ì‘ë‹µ ìš”ì²­
                        final_result = self.parser.stream_and_parse(
                            system_prompt,
                            working_messages,
                            model,
                            pretty_print,
                            tools=None
                        )
                        if final_result:
                            final_response = final_result[0]
                            final_usage = final_result[1]
                        break

            # ì„ì‹œ ë©”ì‹œì§€ì— Assistant ë©”ì‹œì§€ ì¶”ê°€ (tool_calls í¬í•¨)
            # Geminiì˜ ê²½ìš° tool_callsì— thought_signatureê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°,
            # ì´ë¥¼ ê·¸ëŒ€ë¡œ ë³´ì¡´í•´ì•¼ ë‹¤ìŒ í„´ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ
            assistant_message = {
                "role": "assistant",
                "content": response_text if response_text else None,
                "tool_calls": tool_calls  # thought_signatureëŠ” tool_calls ë‚´ë¶€ì— ì´ë¯¸ í¬í•¨ë¨
            }
            working_messages.append(assistant_message)

            # ê° Tool ì‹¤í–‰
            self.console.print(
                f"\n[bold cyan]â”â”â” Tool ì‹¤í–‰ ({len(tool_calls)}ê°œ) â”â”â”[/bold cyan]",
                highlight=False
            )

            tool_results = self.registry.execute_tool_calls(
                tool_calls,
                auto_confirm=False,
                show_result=True
            )

            # ì„ì‹œ ë©”ì‹œì§€ì— Tool ê²°ê³¼ ì¶”ê°€
            for tool_result in tool_results:
                working_messages.append(tool_result)

            self.console.print(
                f"\n[dim]â”â”â” Tool ì‹¤í–‰ ì™„ë£Œ, AIì— ê²°ê³¼ ì „ë‹¬ ì¤‘... (ë°˜ë³µ {iteration}/{self.MAX_ITERATIONS}) â”â”â”[/dim]",
                highlight=False
            )

        # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ê²½ê³ 
        if iteration >= self.MAX_ITERATIONS:
            self.console.print(
                f"\n[yellow]âš ï¸ ìµœëŒ€ Tool ë°˜ë³µ íšŸìˆ˜({self.MAX_ITERATIONS})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.[/yellow]",
                highlight=False
            )

        return final_response, final_usage

    def run_single(
        self,
        system_prompt: Dict[str, Any],
        messages: List[Dict[str, Any]],
        model: str,
        pretty_print: bool = True
    ) -> Optional[Tuple[str, Dict[str, Any]]]:
        """
        Tool ì—†ì´ ë‹¨ì¼ AI í˜¸ì¶œì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        ê¸°ì¡´ì˜ ë‹¨ìˆœ í˜¸ì¶œê³¼ ë™ì¼í•˜ì§€ë§Œ, ë°˜í™˜ê°’ í˜•ì‹ì„ ë§ì¶”ê¸° ìœ„í•œ ë˜í¼ì…ë‹ˆë‹¤.

        Returns:
            (ì‘ë‹µ ë¬¸ìì—´, ì‚¬ìš©ëŸ‰ ì •ë³´) íŠœí”Œ.
            ì‹¤íŒ¨ ì‹œ None.
        """
        result = self.parser.stream_and_parse(
            system_prompt,
            messages,
            model,
            pretty_print,
            tools=None
        )

        if result is None:
            return None

        response_text, usage_info, _ = result
        return response_text, usage_info
